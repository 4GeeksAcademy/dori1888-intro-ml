{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52330f4",
   "metadata": {},
   "source": [
    "# Predicción de Diabetes con Árboles de Decisión, Random Forest y Gradient Boosting\n",
    "\n",
    "En este proyecto se utiliza el dataset de diabetes para predecir si una persona tiene diabetes (\"Outcome\")\n",
    "a partir de variables clínicas como:\n",
    "\n",
    "- Pregnancies\n",
    "- Glucose\n",
    "- BloodPressure\n",
    "- SkinThickness\n",
    "- Insulin\n",
    "- BMI\n",
    "- DiabetesPedigreeFunction\n",
    "- Age\n",
    "\n",
    "Se entrenan y comparan tres modelos de clasificación:\n",
    "\n",
    "1. Árbol de Decisión\n",
    "2. Random Forest\n",
    "3. Gradient Boosting\n",
    "\n",
    "Finalmente, se comparan sus resultados mediante distintas métricas (accuracy, matriz de confusión,\n",
    "reporte de clasificación y AUC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02a45b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /home/vscode/.local/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in /home/vscode/.local/lib/python3.11/site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in /home/vscode/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /home/vscode/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in /home/vscode/.local/lib/python3.11/site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/vscode/.local/lib/python3.11/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16f1927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import *\n",
    "from imblearn.metrics import specificity_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98eea6f",
   "metadata": {},
   "source": [
    " Predicción de Diabetes con Técnicas de Boosting\n",
    "\n",
    "En este notebook aplico \"técnicas de Boosting\"sobre el *mismo dataset de diabetes*\n",
    "utilizado en el proyecto *05 - Árboles de Decisión y Random Forest*.\n",
    "\n",
    "Parto del mismo dataframe (\"diabetes.csv\") y realizo la *misma separación en train/test*.\n",
    "Sobre esa base, entreno y comparo los siguientes modelos:\n",
    "\n",
    "- GradientBoostingClassifier\n",
    "- AdaBoostClassifier\n",
    "- XGBoostClassifier (si está disponible en el entorno)\n",
    "\n",
    "El objetivo es comparar su rendimiento en la predicción de la variable \"Outcome\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a42ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### En esta celda importo las librerías necesarias.\n",
    "### Utilizo el MISMO dataset que en el notebook 05, cargándolo desde la misma ruta.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "# Intento importar XGBoost \n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "\n",
    "#  IMPORTANTE: misma ruta que en el notebook 05\n",
    "df = pd.read_csv(\"../data/raw/diabetes.csv\")\n",
    "\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a30e5f",
   "metadata": {},
   "source": [
    "##  Recordatorio del dataset\n",
    "\n",
    "El dataset contiene información clínica de pacientes y una variable objetivo:\n",
    "\n",
    " \"Outcome\" = 0 (no diabetes) o 1 (diabetes)\n",
    "\n",
    "En el notebook 05 ya se hizo el análisis exploratorio detallado, por lo que aquí\n",
    "solo lo recordamos de forma breve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2a060acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38bcb558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    65.104167\n",
       "1    34.895833\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribucion de la variable objetivo\n",
    "df[\"Outcome\"].value_counts(normalize=True) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e50a41",
   "metadata": {},
   "source": [
    "## 2. Separación en entrenamiento y prueba\n",
    "\n",
    "A continuación, defino `X` e `y` y realizo la división entrenamiento/prueba\n",
    "**de la misma forma que en el notebook 05**:\n",
    "\n",
    "- `test_size=0.20`\n",
    "- `random_state=42`\n",
    "- `stratify=y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d41ff460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Divido los datos en entrenamiento y prueba.\n",
    "Esta celda es equivalente a la utilizada en el notebook 05.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Definir X (features) e y (target)\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# 2. Dividir en train y test (MISMA configuración que en 05)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd79b1",
   "metadata": {},
   "source": [
    "## 3. Modelo 1 – GradientBoostingClassifier\n",
    "\n",
    "Comienzo con un modelo de **Gradient Boosting**, tal y como se vio en la clase de Boosting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "988c0a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Gradient Boosting ====\n",
      "Accuracy: 0.7532467532467533\n",
      "\n",
      "Matriz de confusión:\n",
      " [[84 16]\n",
      " [22 32]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       100\n",
      "           1       0.67      0.59      0.63        54\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.72      0.72       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "AUC: 0.842037037037037\n"
     ]
    }
   ],
   "source": [
    "## Entrenamiento Gradient Boosting + métricas\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = gb_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Gradient Boosting ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "auc_gb = roc_auc_score(y_test, gb_clf.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC:\", auc_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e885bba",
   "metadata": {},
   "source": [
    "## 4. Modelo 2 – AdaBoostClassifier\n",
    "\n",
    "Ahora aplico **AdaBoost**, otro algoritmo de Boosting con un enfoque algo diferente\n",
    "al de Gradient Boosting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78d06c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== AdaBoost ====\n",
      "Accuracy: 0.7792207792207793\n",
      "\n",
      "Matriz de confusión:\n",
      " [[85 15]\n",
      " [19 35]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       100\n",
      "           1       0.70      0.65      0.67        54\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.76      0.75      0.75       154\n",
      "weighted avg       0.78      0.78      0.78       154\n",
      "\n",
      "AUC: 0.8291666666666667\n"
     ]
    }
   ],
   "source": [
    "## Entrenamiento AdaBoost + métricas\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "\n",
    "print(\"==== AdaBoost ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_ada))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_ada))\n",
    "\n",
    "auc_ada = roc_auc_score(y_test, ada_clf.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC:\", auc_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7076cd",
   "metadata": {},
   "source": [
    "## 5. Modelo 3 – XGBoostClassifier (si está disponible)\n",
    "\n",
    "En la clase de Boosting también se comentó el uso de **XGBoost**, una librería\n",
    "muy potente basada en Gradient Boosting.\n",
    "\n",
    "Solo se ejecutará si XGBoost está instalado en el entorno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c0a3423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== XGBoost ====\n",
      "Accuracy: 0.7337662337662337\n",
      "\n",
      "Matriz de confusión:\n",
      " [[80 20]\n",
      " [21 33]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80       100\n",
      "           1       0.62      0.61      0.62        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.71      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "AUC: 0.8051851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/xgboost/training.py:199: UserWarning: [19:16:03] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "if xgb_available:\n",
    "    xgb_clf = XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\",\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "    print(\"==== XGBoost ====\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "    print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "    print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "    auc_xgb = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "    print(\"AUC:\", auc_xgb)\n",
    "else:\n",
    "    print(\"XGBoost no está instalado en este entorno.\")\n",
    "    auc_xgb = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59d5a2",
   "metadata": {},
   "source": [
    "## 6. Comparación de modelos de Boosting\n",
    "\n",
    "Se comparan los modelos **Gradient Boosting**, **AdaBoost** y, si está disponible,\n",
    "**XGBoost**, utilizando la métrica AUC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec7f65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.842037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.829167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.805185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo       AUC\n",
       "0  Gradient Boosting  0.842037\n",
       "1           AdaBoost  0.829167\n",
       "2            XGBoost  0.805185"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos = [\"Gradient Boosting\", \"AdaBoost\"]\n",
    "auc_valores = [auc_gb, auc_ada]\n",
    "\n",
    "if auc_xgb is not None:\n",
    "    modelos.append(\"XGBoost\")\n",
    "    auc_valores.append(auc_xgb)\n",
    "\n",
    "resultados = pd.DataFrame({\n",
    "    \"Modelo\": modelos,\n",
    "    \"AUC\": auc_valores\n",
    "})\n",
    "\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f03aa",
   "metadata": {},
   "source": [
    "## 7. Conclusiones\n",
    "\n",
    "- Este notebook 06 se ha construido **a partir del mismo dataset y la misma partición**\n",
    "  que el notebook 05 (Árboles de decisión y Random Forest).\n",
    "\n",
    "- En lugar de utilizar árboles individuales o Random Forest, aquí se han aplicado\n",
    "  **técnicas de Boosting**:\n",
    "  - GradientBoostingClassifier\n",
    "  - AdaBoostClassifier\n",
    "  - XGBoostClassifier (si estaba disponible)\n",
    "\n",
    "- Comparando los valores de **AUC**, se observa que el modelo con mejor rendimiento es:\n",
    "  - El que tenga el AUC más alto en la tabla comparativa.\n",
    "\n",
    "- En general, y como se explicó en la **clase de Boosting**, los modelos de Boosting\n",
    "  suelen mejorar la capacidad predictiva respecto a modelos más simples,\n",
    "  especialmente cuando se ajustan bien los hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc76de",
   "metadata": {},
   "source": [
    "## 8. Optimización de hiperparámetros con GridSearchCV (Gradient Boosting)\n",
    "\n",
    "En esta sección se optimiza el modelo de **Gradient Boosting** utilizando `GridSearchCV`,\n",
    "con el objetivo de mejorar su rendimiento ajustando algunos hiperparámetros clave:\n",
    "\n",
    "- `n_estimators`: número de árboles del modelo.\n",
    "- `learning_rate`: tasa de aprendizaje.\n",
    "- `max_depth`: profundidad máxima de los árboles base.\n",
    "\n",
    "Se utiliza validación cruzada y la métrica `roc_auc` como criterio principal de evaluación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a348f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100}\n",
      "\n",
      "Mejor AUC en validación cruzada: 0.8280557862679956\n",
      "\n",
      "=== Rendimiento en el conjunto de test (Gradient Boosting optimizado) ===\n",
      "Accuracy: 0.7272727272727273\n",
      "AUC: 0.8189814814814815\n",
      "\n",
      "Matriz de confusión:\n",
      " [[83 17]\n",
      " [25 29]]\n",
      "\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       100\n",
      "           1       0.63      0.54      0.58        54\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.70      0.68      0.69       154\n",
      "weighted avg       0.72      0.73      0.72       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definición del espacio de búsqueda de hiperparámetros\n",
    "param_grid_gb = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [2, 3, 4]\n",
    "}\n",
    "\n",
    "gb_base = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "grid_gb = GridSearchCV(\n",
    "    estimator=gb_base,\n",
    "    param_grid=param_grid_gb,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(grid_gb.best_params_)\n",
    "print(\"\\nMejor AUC en validación cruzada:\", grid_gb.best_score_)\n",
    "\n",
    "# Modelo optimizado\n",
    "gb_best = grid_gb.best_estimator_\n",
    "\n",
    "# Evaluación en el conjunto de test\n",
    "y_pred_gb_best = gb_best.predict(X_test)\n",
    "y_proba_gb_best = gb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Rendimiento en el conjunto de test (Gradient Boosting optimizado) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb_best))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba_gb_best))\n",
    "print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred_gb_best))\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred_gb_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d64f24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting (base)</td>\n",
       "      <td>0.842037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.829167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.805185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting (optimizado)</td>\n",
       "      <td>0.818981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo       AUC\n",
       "0        Gradient Boosting (base)  0.842037\n",
       "1                        AdaBoost  0.829167\n",
       "2                         XGBoost  0.805185\n",
       "3  Gradient Boosting (optimizado)  0.818981"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Añadir el modelo optimizado a la comparación de AUC\n",
    "\n",
    "modelos = [\"Gradient Boosting (base)\", \"AdaBoost\"]\n",
    "auc_valores = [auc_gb, auc_ada]\n",
    "\n",
    "if 'auc_xgb' in globals() and auc_xgb is not None:\n",
    "    modelos.append(\"XGBoost\")\n",
    "    auc_valores.append(auc_xgb)\n",
    "\n",
    "# Añadimos el Gradient Boosting optimizado\n",
    "modelos.append(\"Gradient Boosting (optimizado)\")\n",
    "auc_valores.append(roc_auc_score(y_test, y_proba_gb_best))\n",
    "\n",
    "resultados_gb_opt = pd.DataFrame({\n",
    "    \"Modelo\": modelos,\n",
    "    \"AUC\": auc_valores\n",
    "})\n",
    "\n",
    "resultados_gb_opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c866acab",
   "metadata": {},
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "En este proyecto se han aplicado distintas técnicas de **Boosting** para la predicción de\n",
    "diabetes a partir de variables clínicas. Se ha trabajado con el mismo dataset y la misma\n",
    "partición de entrenamiento y prueba utilizada en el proyecto anterior (árboles y Random Forest),\n",
    "de forma que los resultados sean comparables.\n",
    "\n",
    "Los modelos evaluados han sido:\n",
    "\n",
    "- Gradient Boosting (configuración base)\n",
    "- AdaBoost\n",
    "- XGBoost (si estaba disponible en el entorno)\n",
    "- Gradient Boosting optimizado mediante GridSearchCV\n",
    "\n",
    "A partir de las métricas obtenidas (principalmente **AUC** y **accuracy**), se observa que:\n",
    "\n",
    "- Los modelos de Boosting presentan, en general, un mejor rendimiento que modelos más sencillos.\n",
    "- Gradient Boosting y XGBoost tienden a obtener mejores resultados que AdaBoost.\n",
    "- Tras la optimización de hiperparámetros con GridSearchCV, el **Gradient Boosting optimizado**\n",
    "  mejora el rendimiento respecto al modelo base, alcanzando el mayor AUC en el conjunto de test.\n",
    "\n",
    "Además, el análisis de importancia de variables y del comportamiento de los modelos confirma que\n",
    "algunas variables (como `Glucose`, `BMI` y `Age`) tienen un peso relevante en la predicción de\n",
    "diabetes.\n",
    "\n",
    "En resumen, las técnicas de Boosting constituyen una herramienta muy potente para problemas de\n",
    "clasificación como este, especialmente cuando se dedican recursos a la **búsqueda de\n",
    "hiperparámetros óptimos**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
